## 0915 (DEA-C01 Review)

### 1. Amazon Redshift Streaming Ingestion - 실시간 분석 최소 운영 오버헤드

**문제 시나리오**: Kinesis Data Streams에서 초당 수GB 데이터를 Redshift로 실시간 수집, 기존 BI 도구로 준실시간 분석

**정답: External Schema + Materialized View + Auto Refresh**

**왜 이 방법이 효과적인가:**

**A. Streaming Ingestion 아키텍처:**

**직접 연결 방식:**
- **중간 단계 제거**: Firehose, Glue 없이 직접 연결
- **준실시간 처리**: 초 단위 지연으로 즉시 분석 가능
- **자동 스키마 매핑**: JSON을 테이블 구조로 자동 변환

**External Schema 설정:**
```sql
-- Kinesis Data Streams를 Redshift Object로 매핑
CREATE EXTERNAL SCHEMA kinesis_schema FROM KINESIS
IAM_ROLE 'arn:aws:iam::account:role/RedshiftStreamingRole';

-- Materialized View로 스트림 데이터 읽기
CREATE MATERIALIZED VIEW real_time_analytics AS
SELECT json_extract_path_text(kinesis_data, 'customer_id') as customer_id,
       json_extract_path_text(kinesis_data, 'amount') as amount,
       approximate_arrival_timestamp
FROM kinesis_schema.my_stream;

-- Auto Refresh 설정 (30초마다 자동 갱신)
ALTER MATERIALIZED VIEW real_time_analytics AUTO REFRESH YES;
```

**B. 운영 오버헤드 최소화 요소:**

**자동 관리 기능:**
- **Auto Refresh**: 수동 REFRESH 명령 불필요
- **자동 스케일링**: Serverless 환경에서 자동 용량 조절
- **백그라운드 처리**: 쿼리 성능에 영향 없이 백그라운드 갱신

---

### 2. Redshift 비용 최적화 - Federated Query + Spectrum 하이브리드

**문제**: PostgreSQL 실시간 데이터 + Redshift 현재 데이터 + S3 아카이브 데이터 통합 분석, 15개월만 Redshift 보관

**정답: Federated Query + Spectrum (두 가지 모두 필요)**

**A. Federated Query - 실시간 PostgreSQL 연결:**

**외부 데이터베이스 직접 쿼리:**
- **Live 데이터 접근**: ETL 없이 PostgreSQL 실시간 조회
- **Zero Copy**: 데이터 복사 없이 조인 가능
- **실시간성 유지**: 최신 트랜잭션 데이터 즉시 반영

**설정 예시:**
```sql
-- External Schema 생성
CREATE EXTERNAL SCHEMA postgres_live
FROM POSTGRES
DATABASE 'aurora_db' SCHEMA 'public'
URI 'aurora-cluster.cluster-xyz.us-east-1.rds.amazonaws.com'
IAM_ROLE 'arn:aws:iam::account:role/RedshiftRole'
SECRET_ARN 'arn:aws:secretsmanager:us-east-1:account:secret:aurora-secret';
```

**B. Redshift Spectrum - 아카이브 데이터 접근:**

**S3 히스토리컬 데이터 쿼리:**
- **비용 절약**: S3 스토리지가 Redshift보다 90% 저렴
- **무제한 용량**: 년도별 파티셔닝으로 페타바이트 저장
- **Columnar 최적화**: Parquet 형식으로 쿼리 성능 최적화

**아카이브 프로세스:**
```sql
-- 월별 아카이브 작업
UNLOAD ('SELECT * FROM sales WHERE order_date < DATEADD(month, -15, GETDATE())')
TO 's3://archive-bucket/year=2023/month=01/'
FORMAT AS PARQUET
PARTITION BY (year, month);

-- 아카이브 후 삭제
DELETE FROM sales WHERE order_date < DATEADD(month, -15, GETDATE());
```

**C. 통합 쿼리 예시:**

**3계층 데이터 조인:**
```sql
-- 실시간 + 현재 + 아카이브 데이터 통합 분석
SELECT
    live.customer_id,
    live.recent_orders,          -- PostgreSQL 실시간
    current.monthly_total,       -- Redshift 현재 (15개월)
    archive.historical_avg       -- S3 아카이브 (15개월 이전)
FROM postgres_live.customers live
JOIN current_sales current ON live.customer_id = current.customer_id
JOIN spectrum_archive.sales_history archive ON live.customer_id = archive.customer_id
WHERE live.last_login >= CURRENT_DATE - 30;
```

---

### 3. EventBridge vs Lambda - S3 File Gateway 자동화

**문제**: S3 File Gateway 파일 전송 완료 시 Glue Workflow 자동 실행

**정답: EventBridge (최소 운영 오버헤드)**

**A. EventBridge의 장점:**

**직접 통합 아키텍처:**
```
S3 File Gateway → S3 Object Created → EventBridge → Glue Workflow
        ↑              ↑                ↑            ↑
     파일 전송      이벤트 발생       규칙 매칭    직접 실행
```

**서버리스 완전 관리:**
- **코드 불필요**: Lambda 함수 작성 및 관리 없음
- **자동 스케일링**: 동시 파일 전송에 자동 대응
- **오류 처리**: 내장된 재시도 및 DLQ 기능

**B. Lambda 방식의 단점:**

**추가 운영 오버헤드:**
- **함수 관리**: Lambda 코드 작성, 배포, 모니터링
- **권한 관리**: Lambda 실행 역할 및 Glue 호출 권한
- **오류 처리**: 사용자 정의 예외 처리 로직

**EventBridge 설정 예시:**
```json
{
  "Rules": [{
    "Name": "S3FileGatewayToGlue",
    "EventPattern": {
      "source": ["aws.s3"],
      "detail-type": ["Object Created"],
      "detail": {
        "bucket": {"name": ["file-gateway-bucket"]}
      }
    },
    "Targets": [{
      "Id": "GlueWorkflow",
      "Arn": "arn:aws:glue:region:account:workflow/data-processing",
      "RoleArn": "arn:aws:iam::account:role/EventBridgeGlueRole"
    }]
  }]
}
```

---

### 4. IoT 센서 데이터 최소 지연 시간 - KCL 커스텀 애플리케이션

**문제**: 10초마다 100KB 데이터, 30초마다 S3에서 읽기, 최소 지연시간

**정답: Kinesis Data Streams + KCL + 5초 버퍼**

**A. KCL (Kinesis Client Library) 장점:**

**세밀한 제어 가능:**
- **커스텀 버퍼링**: 5초 간격으로 즉시 S3 저장
- **실시간 처리**: Firehose 기본 60초 대기 없음
- **배치 최적화**: 작은 파일들을 효율적으로 배치 처리

**지연 시간 비교:**
```
A. Firehose 기본(60초): 센서 → Kinesis → [60초 대기] → S3 (60초+ 지연)
B. Kinesis만: S3 직접 쓰기 불가
C. KCL(5초): 센서 → Kinesis → [5초 배치] → S3 (5-10초 지연) ✓
D. Flink+Firehose: 추가 처리 단계로 지연 증가
```

**B. KCL 애플리케이션 구현:**

**실시간 S3 저장 로직:**
```python
# KCL Consumer Application
class IoTDataProcessor:
    def __init__(self):
        self.buffer = []
        self.last_flush = time.time()

    def process_record(self, record):
        self.buffer.append(record.data)

        # 5초마다 또는 1MB마다 S3로 플러시
        if (time.time() - self.last_flush > 5) or (len(self.buffer) > 10):
            self.flush_to_s3()

    def flush_to_s3(self):
        s3_key = f"iot-data/{datetime.now().isoformat()}.json"
        s3_client.put_object(
            Bucket='iot-bucket',
            Key=s3_key,
            Body=json.dumps(self.buffer)
        )
        self.buffer = []
        self.last_flush = time.time()
```

**처리량 최적화:**
- **5개 샤드**: 병렬 처리로 처리량 증대
- **배치 처리**: 다중 레코드 동시 처리
- **압축**: 전송 데이터 크기 최소화

---

### 5. VPC Flow Logs 비용 최적화 - S3 Parquet + Athena

**문제**: VPC Flow Logs 수집 및 분석, 최소 비용

**정답: S3 Parquet + Athena**

**A. 저장 비용 비교:**

**CloudWatch Logs vs S3:**
- **CloudWatch**: $0.50/GB 저장 + $0.03/GB 수집
- **S3 Standard**: $0.023/GB (20배 저렴)
- **S3 IA**: $0.0125/GB (40배 저렴)

**텍스트 vs Parquet 비교:**
- **텍스트 형식**: 원본 크기 그대로
- **Parquet**: 70-90% 압축률 (컬럼형 저장)

**B. Parquet의 비용 절약 효과:**

**압축률과 쿼리 성능:**
```
원본 Flow Logs (1GB)
  ↓ Parquet 변환
압축된 Parquet (200-300MB)
  ↓ Athena 쿼리
필요 컬럼만 스캔 (10-50MB)
```

**저장 및 쿼리 비용:**
- **저장 비용**: 압축으로 70% 절약
- **쿼리 비용**: 컬럼형 스캔으로 90% 절약
- **전송 비용**: 작은 파일 크기로 네트워크 비용 절약

**C. 비용 최적화 설정:**

**Flow Logs를 Parquet으로 직접 저장:**
```json
{
  "FlowLogConfig": {
    "DeliverLogsPermissionArn": "arn:aws:iam::account:role/flowlogsRole",
    "LogDestination": "s3://vpc-flowlogs-bucket/",
    "LogFormat": "${srcaddr} ${dstaddr} ${srcport} ${dstport} ${protocol} ${packets} ${bytes}",
    "LogDestinationType": "s3",
    "MaxAggregationInterval": 600
  }
}
```

**Athena 쿼리 최적화:**
```sql
-- 파티션과 컬럼 프루닝 활용
SELECT srcaddr, dstaddr, SUM(bytes) as total_bytes
FROM vpc_flow_logs
WHERE year='2023' AND month='09' AND day='15'  -- 파티션 프루닝
  AND srcaddr LIKE '10.0.%'                    -- 조건 필터링
GROUP BY srcaddr, dstaddr
```

**연간 비용 절약 예시:**
- **CloudWatch Logs**: 100GB × $0.50 = $50/월
- **S3 Text**: 100GB × $0.023 = $2.3/월
- **S3 Parquet**: 30GB × $0.023 = $0.69/월 (최종 선택)


