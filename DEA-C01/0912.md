## 0912 (DEA-C01 Review)

### 1. Redshift 분산 키 최적화 - 노드 간 부하 불균형 해결

**문제 시나리오**: RA3.4xlarge 5노드 Redshift 클러스터, 하나 노드 CPU 90% 과부하, 나머지 4노드 15% 저사용률, 노드 수 유지하면서 부하 균등화

**정답: distribution key를 가장 큰 dimension을 가진 컬럼으로 변경**

**왜 이 방법이 효과적인가:**

**A. Key Distribution의 부하 불균형 원인:**

**현재 문제 상황:**
- **데이터 집중**: 특정 키 값이 한 노드에 집중
- **핫스팟 발생**: 인기 키 값으로 인한 쿼리 집중
- **자원 낭비**: 4개 노드가 놀고 있음

**부하 불균형 예시:**
```sql
-- 잘못된 분산 키 (지역 코드)
CREATE TABLE sales (
  sale_id INT,
  region_code CHAR(2),  -- 서울: 80%, 기타: 20% 분산
  product_id INT,
  amount DECIMAL
) DISTKEY(region_code);  -- 불균형 발생
```

**B. 가장 큰 Dimension이 좋은 이유:**

**고유값 수 최대화:**
- **균등 분산**: 많은 고유값으로 데이터 고른 분산
- **핫스팟 방지**: 특정 값 집중 최소화
- **JOIN 최적화**: 큰 팩트 테이블의 분산 키로 적합

**최적화된 분산 키 예시:**
```sql
-- 개선된 분산 키 (고유값이 많은 컬럼)
CREATE TABLE sales (
  sale_id INT,
  region_code CHAR(2),
  product_id INT,        -- 10,000개 제품 (고유값 많음)
  amount DECIMAL
) DISTKEY(product_id);   -- 균등 분산
```

---

### 2. AWS CloudTrail Events 차이점 - Management vs Data Events

**문제**: Management Events와 Data Events의 차이점 설명

**A. Management Events (관리 이벤트):**

**정의 및 범위:**
- **리소스 관리**: AWS 리소스의 생성, 수정, 삭제
- **API 호출**: Control Plane 작업
- **계정 수준**: AWS 계정 전체 관리 작업

**주요 예시:**
- EC2 인스턴스 생성/종료
- IAM 정책 변경
- VPC 생성/수정
- RDS 스냅샷 생성

**B. Data Events (데이터 이벤트):**

**정의 및 범위:**
- **데이터 접근**: 리소스 내부 데이터 조작
- **Data Plane**: 실제 데이터 읽기/쓰기
- **고빈도**: 대량의 이벤트 발생

**주요 예시:**
- S3 객체 업로드/다운로드
- DynamoDB 레코드 읽기/쓰기
- Lambda 함수 실행

**C. S3 파일 업로드의 경우:**

**Data Events에 해당하는 이유:**
- **파일 데이터 조작**: 객체 생성/수정
- **버킷 내부 작업**: 버킷 자체가 아닌 내용물 변경
- **빈번한 발생**: 애플리케이션 레벨 작업

---

### 3. Amazon Redshift ALL Distribution Style

**문제**: ALL distribution이란 무엇인가?

**A. ALL Distribution 작동 원리:**

**데이터 복제 방식:**
- **전체 복사**: 모든 노드에 테이블 전체 데이터 복사
- **로컬 접근**: 각 노드에서 JOIN 시 로컬 데이터 사용
- **네트워크 절약**: 노드 간 데이터 이동 불필요

**아키텍처 구조:**
```
Node 1: Table A (전체) + Table B (일부)
Node 2: Table A (전체) + Table B (일부)
Node 3: Table A (전체) + Table B (일부)
       ↑
   ALL Distribution
```

**B. 최적 사용 케이스:**

**작은 테이블 (10MB 미만):**
- **Dimension 테이블**: 제품, 고객, 지역 정보
- **참조 테이블**: 코드 테이블, 설정 값
- **드물게 변경**: 자주 업데이트되지 않는 데이터

**성능 향상 효과:**
- **JOIN 성능**: 로컬 JOIN으로 네트워크 I/O 제거
- **쿼리 병렬화**: 모든 노드가 독립적으로 처리
- **응답 시간 단축**: 네트워크 지연 최소화

---

### 4. AWS Glue DataBrew COUNT_DISTINCT - 최소 운영 노력

**문제**: 2GB .xls 파일에서 중복 제거된 고객 수 계산

**A. DataBrew의 GUI 기반 장점:**

**시각적 데이터 준비:**
- **코딩 불필요**: 드래그 앤 드롭 인터페이스
- **즉시 미리보기**: 변환 결과 실시간 확인
- **직관적 조작**: 비개발자도 사용 가능

**대용량 파일 처리:**
- **자동 최적화**: 2GB 파일 효율적 처리
- **병렬 처리**: 내부적으로 분산 처리
- **메모리 관리**: 자동 청크 단위 처리

**B. COUNT_DISTINCT 함수의 효율성:**

**내장 집계 함수:**
```
Recipe Step:
1. 이름 컬럼 concatenate (First + Last)
2. COUNT_DISTINCT aggregate function 적용
3. 결과 S3 또는 다른 대상에 저장
```

**대안 방법 대비 장점:**
- **Spark/Glue Job**: 코딩 + 클러스터 관리 필요
- **Lambda**: 메모리 제한으로 2GB 처리 어려움
- **Athena**: 테이블 생성 + SQL 작성 필요

---

### 5. Amazon Athena 다중 데이터 소스 쿼리

**문제**: 다양한 데이터 소스(S3, RDS, DynamoDB, Redshift)를 통합 쿼리

**A. 통합 아키텍처:**

**Data Catalog 중심 설계:**
```
AWS Glue Crawler → Data Catalog → Amazon Athena
       ↑              ↑              ↓
각 데이터 소스       메타데이터      통합 쿼리
스키마 수집         통합 저장       SQL/PartiQL
```

**B. 데이터 소스별 처리:**

**구조화된 데이터 (SQL):**
- **RDS**: JDBC 연결을 통한 스키마 크롤링
- **Redshift**: Spectrum을 통한 데이터 접근
- **S3 CSV**: 구조화된 형태로 스키마 추론

**반구조화된 데이터 (PartiQL):**
- **DynamoDB**: NoSQL 구조를 SQL-like로 쿼리
- **S3 JSON**: 중첩 구조 탐색 가능
- **복잡한 타입**: 배열, 객체 등 처리

**C. 쿼리 예시:**

**SQL (구조화된 데이터):**
```sql
SELECT customer_id, SUM(amount)
FROM rds_sales_table
JOIN redshift_customer_table ON customer_id
GROUP BY customer_id
```

**PartiQL (JSON 데이터):**
```sql
SELECT customer.name, order.items[0].product
FROM s3_json_table
WHERE customer.region = 'Seoul'
```

---

### 6. SageMaker Studio + AWS Glue Interactive Sessions

**문제**: SageMaker Studio에서 Glue 세션 사용 시 접근 거부 오류

**A. 역할 가정(AssumeRole) 필요성:**

**서비스 간 권한 위임:**
- **SageMaker Studio**: 사용자 환경
- **Glue Interactive Sessions**: 별도 실행 환경
- **권한 bridge**: sts:AssumeRole로 연결

**B. 신뢰 정책 구성:**

**IAM 정책 설정:**
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": "sts:AssumeRole",
      "Resource": [
        "arn:aws:iam::account:role/GlueServiceRole",
        "arn:aws:iam::account:role/SageMakerServiceRole"
      ]
    }
  ]
}
```

**신뢰 관계 설정:**
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Service": ["glue.amazonaws.com", "sagemaker.amazonaws.com"]
      },
      "Action": "sts:AssumeRole"
    }
  ]
}
```

---

### 7. S3 Object Lambda를 통한 동적 PII 마스킹

**문제**: 애플리케이션별로 다른 PII 마스킹 요구사항, 최소 운영 오버헤드

**A. S3 Object Lambda 작동 원리:**

**실시간 데이터 변환:**
```
Application → S3 Object Lambda → Lambda Function → Original S3 Object
     ↑              ↑                  ↑              ↑
 GET 요청    요청 가로채기        데이터 변환      원본 데이터 유지
```

**B. 애플리케이션별 마스킹:**

**Lambda 함수 로직:**
```python
def lambda_handler(event, context):
    # 요청 애플리케이션 식별
    app_id = event['getObjectContext']['requestRoute']

    if app_id == 'analytics-app':
        # PII 완전 제거
        return mask_all_pii(data)
    elif app_id == 'ecommerce-app':
        # 부분 마스킹 (이메일 일부만)
        return partial_mask_pii(data)
```

**C. 운영 오버헤드 최소화:**

**중앙집중식 관리:**
- **원본 유지**: 하나의 원본 데이터로 다양한 뷰 제공
- **정책 중앙화**: 하나의 Lambda 함수에서 모든 규칙 관리
- **자동 적용**: 새로운 애플리케이션 자동으로 정책 적용

---

### 8. Redshift Spectrum 성능 최적화 - Columnar Storage

**문제**: S3 데이터를 Redshift Spectrum으로 쿼리할 때 최고 성능

**A. Columnar Storage Format이란:**

**컬럼 지향 저장:**
- **Parquet**: Apache에서 개발한 오픈소스 형식
- **ORC**: Optimized Row Columnar, Hive 최적화
- **압축 효율**: 같은 타입 데이터 연속 저장으로 고압축

**행 vs 컬럼 저장 비교:**
```
Row Format (CSV):
1,John,25,Engineer | 2,Jane,30,Manager | 3,Bob,28,Developer

Column Format (Parquet):
ID: 1,2,3
Name: John,Jane,Bob
Age: 25,30,28
Job: Engineer,Manager,Developer
```

**B. Spectrum 성능 향상 이유:**

**필요한 컬럼만 읽기:**
- **I/O 최소화**: SELECT age FROM table → age 컬럼만 읽음
- **네트워크 절약**: S3에서 필요한 데이터만 전송
- **메모리 효율**: 불필요한 데이터 메모리에 로드 안함

**압축률과 성능:**
- **저장 공간**: 50-80% 크기 감소
- **전송 시간**: 네트워크 전송 시간 단축
- **쿼리 속도**: 3-10배 성능 향상

---

### 9. Lambda VPC 연결과 보안 그룹 Self-Reference

**문제**: Lambda가 private 서브넷의 RDS에 연결, 최소 운영 오버헤드

**A. Self-Reference 보안 그룹 설정:**

**동일 보안 그룹 적용:**
```
Lambda Function ←→ RDS Instance
      ↑               ↑
동일한 Security Group 연결
```

**보안 그룹 규칙:**
```
Inbound Rules:
Type: MySQL/Aurora (3306)
Source: sg-12345678 (자기 자신)
Description: Allow access from same security group
```

**B. Self-Reference의 장점:**

**자동 상호 통신:**
- **양방향 허용**: 같은 그룹 멤버끼리 자유 통신
- **IP 관리 불필요**: CIDR 블록 계산 없음
- **동적 적응**: 새로운 리소스 추가 시 자동 허용

**운영 오버헤드 최소화:**
- **단일 설정**: 하나의 보안 그룹만 관리
- **자동 확장**: 추가 Lambda/RDS 자동 허용
- **IP 변경 무관**: 동적 IP 할당에 영향 없음

---

### 10. SQL Server to S3 Parquet 마이그레이션

**문제**: EC2 SQL Server에서 복잡한 JOIN 결과를 매일 Parquet으로 S3에 저장

**A. View를 사용하는 이유:**

**복잡성 캡슐화:**
- **JOIN 단순화**: 복잡한 다중 테이블 JOIN을 하나의 View로
- **성능 최적화**: SQL Server에서 최적화된 실행 계획
- **재사용성**: 다른 도구에서도 동일한 View 활용

**View 생성 예시:**
```sql
CREATE VIEW daily_analytics AS
SELECT
    c.customer_id,
    c.customer_name,
    SUM(o.amount) as total_amount,
    COUNT(o.order_id) as order_count
FROM customers c
JOIN orders o ON c.customer_id = o.customer_id
JOIN products p ON o.product_id = p.product_id
WHERE o.order_date >= DATEADD(day, -1, GETDATE())
GROUP BY c.customer_id, c.customer_name
```

**B. AWS Glue Job의 효율성:**

**ETL 파이프라인 자동화:**
```python
# Glue Job Script
datasource = glueContext.create_dynamic_frame.from_catalog(
    database="sqlserver_db",
    table_name="daily_analytics_view"
)

# Parquet 변환 및 S3 저장
glueContext.write_dynamic_frame.from_options(
    frame=datasource,
    connection_type="s3",
    connection_options={"path": "s3://analytics-bucket/daily/"},
    format="parquet"
)
```

**운영 효율성:**
- **스케줄 자동화**: CloudWatch Events로 매일 실행
- **오류 처리**: 자동 재시도 및 알람
- **확장성**: 데이터 증가에 따른 자동 리소스 조절

---

### 11. AWS Glue Workflow와 스키마 변경 대응

**문제**: 15분마다 변경되는 스키마에 대응하는 ETL 파이프라인

**A. 두 가지 트리거 방식:**

**시간 기반 (EventBridge Rule):**
- **정기 실행**: 15분마다 자동 실행
- **예측 가능**: 일정한 간격으로 처리
- **배치 처리**: 누적된 파일들을 한번에 처리

**이벤트 기반 (Lambda + S3):**
- **즉시 처리**: 파일 업로드 즉시 처리 시작
- **실시간성**: 지연 시간 최소화
- **개별 처리**: 파일별 독립 처리

**B. Crawler → Job 순서의 중요성:**

**스키마 변경 대응 과정:**
```
파일 업로드 → Crawler 실행 → 스키마 업데이트 → Job 실행 → 데이터 로드
     ↑           ↑             ↑            ↑         ↑
새로운 컬럼    스키마 탐지    Data Catalog   변환 처리   Redshift
```

**Workflow On-demand Trigger:**
- **순서 보장**: Crawler 완료 후 Job 실행
- **의존성 관리**: 이전 단계 성공 시에만 다음 단계
- **오류 격리**: 단계별 독립적 오류 처리

---

### 12. EBS gp2 → gp3 온라인 마이그레이션

**문제**: EC2 인스턴스 중단 없이 EBS 볼륨 타입 변경

**A. 온라인 볼륨 수정:**

**실시간 변경 가능:**
- **무중단 수정**: 인스턴스 실행 중에도 변경 가능
- **점진적 적용**: 백그라운드에서 천천히 마이그레이션
- **성능 즉시 적용**: 새로운 성능 특성 바로 적용

**변경 과정:**
```bash
# AWS CLI로 볼륨 타입 변경
aws ec2 modify-volume \
  --volume-id vol-12345678 \
  --volume-type gp3 \
  --iops 3000 \
  --throughput 125
```

**B. gp3의 장점:**

**성능과 비용 분리:**
- **기본 성능**: 3,000 IOPS, 125 MB/s throughput
- **독립적 조정**: IOPS와 처리량을 별도로 설정
- **비용 절약**: gp2 대비 20% 저렴

**실시간 조정:**
- **IOPS**: 3,000 ~ 16,000 범위에서 조정
- **처리량**: 125 ~ 1,000 MB/s 범위에서 조정
- **즉시 적용**: 재부팅 없이 성능 변경

---

### 13. Amazon Redshift Streaming Ingestion

**문제**: Kinesis Data Streams에서 Redshift Serverless로 실시간 데이터 저장

**A. Streaming Ingestion 기능:**

**직접 연결 아키텍처:**
```
Kinesis Data Streams → Redshift Serverless → 실시간 분석
        ↑                   ↑                 ↓
실시간 데이터 수집      직접 테이블 적재    초단위 쿼리 가능
```

**중간 단계 제거:**
- **ETL 불필요**: Firehose, Glue 등 중간 처리 생략
- **지연 최소화**: 초 단위 지연으로 준실시간 처리
- **자동 변환**: JSON을 테이블 구조로 자동 매핑

**B. 설정 및 사용:**

**Streaming Ingestion 활성화:**
```sql
-- Redshift에서 직접 스트림 생성
CREATE STREAM my_stream FROM 'arn:aws:kinesis:region:account:stream/my-kinesis-stream'
IAM_ROLE 'arn:aws:iam::account:role/RedshiftStreamingRole';

-- 실시간 쿼리 가능
SELECT * FROM my_stream
WHERE approximate_arrival_timestamp >= SYSDATE - INTERVAL '1 hour';
```

**운영 오버헤드 최소화:**
- **자동 스케일링**: Serverless가 자동으로 용량 조절
- **관리 불필요**: 별도 ETL 파이프라인 관리 없음
- **비용 최적화**: 사용한 만큼만 과금

시험 포인트:
- **실시간 + 최소 운영** = Streaming Ingestion
- **복잡한 ETL 대신** = 직접 연결 방식 선호
- **Serverless 활용** = 자동 관리 및 스케일링