## 0904 (~page 22)

### 1. S3 Object Lambda - 동적 PII 필터링

**문제 시나리오**: 전자상거래 애플리케이션(PII 포함) + 내부 분석 애플리케이션(PII 불필요), 동일 S3 데이터 사용

**해결책: S3 Object Lambda**

S3 Object Lambda 특징:
- **동적 변환**: 요청 시점에 데이터 변환/필터링
- **애플리케이션별 처리**: 요청 소스에 따른 다른 처리 로직
- **원본 보존**: S3 원본 데이터 변경 없이 뷰 제공
- **서버리스**: Lambda 기반 자동 스케일링

아키텍처:
```
S3 버킷 (원본 데이터)
    ↓
S3 Object Lambda Endpoint
    ↓
Lambda 함수 (필터링 로직)
    ↓
┌─────────────┬─────────────────┐
│ 전자상거래   │ 내부 분석        │
│ (PII 포함)  │ (PII 제거됨)    │
└─────────────┴─────────────────┘
```

Lambda 함수 예시:
```python
def lambda_handler(event, context):
    # 요청 컨텍스트 확인
    user_identity = event['userIdentity']
    
    # S3에서 원본 객체 가져오기
    response = s3.get_object(
        Bucket=event['s3Bucket'],
        Key=event['s3Key']
    )
    
    data = json.loads(response['Body'].read())
    
    # PII 필터링 로직
    if 'analytics' in user_identity.get('type', ''):
        # 내부 분석용: PII 제거
        filtered_data = redact_pii(data)
    else:
        # 전자상거래용: 원본 데이터
        filtered_data = data
    
    return {
        'statusCode': 200,
        'body': json.dumps(filtered_data)
    }
```

시험 포인트:
- 동적 데이터 필터링 + 애플리케이션별 액세스 = S3 Object Lambda

### 2. CloudWatch Logs → Splunk 실시간 전송

**문제 시나리오**: VPC Flow Logs → CloudWatch Logs → Splunk, 실시간 전송, 최소 운영 오버헤드

**해결책 비교: Kinesis Data Streams vs Kinesis Data Firehose**

**정답: Kinesis Data Firehose**

**Kinesis Data Firehose 장점:**
- **완전 관리형**: 서버리스, 자동 스케일링
- **Splunk 네이티브 지원**: 사전 구축된 Splunk 커넥터
- **버퍼링**: 배치 처리로 효율적 전송
- **압축**: 자동 데이터 압축으로 비용 절약
- **에러 처리**: 실패 시 S3 백업

**Kinesis Data Streams 단점:**
- **수동 관리**: 샤드 관리 및 스케일링 필요
- **추가 처리**: Splunk 전송을 위한 별도 애플리케이션 필요
- **복잡성**: 높은 운영 오버헤드

아키텍처:
```
VPC Flow Logs → CloudWatch Logs → Subscription Filter → Kinesis Data Firehose → Splunk
```

설정:
```json
{
  "DeliveryStreamName": "splunk-delivery-stream",
  "SplunkDestinationConfiguration": {
    "HECEndpoint": "https://splunk-hec-endpoint",
    "HECToken": "your-hec-token",
    "HECEndpointType": "Event",
    "ProcessingConfiguration": {
      "Enabled": true,
      "Processors": [
        {
          "Type": "Lambda",
          "Parameters": [
            {
              "ParameterName": "LambdaArn",
              "ParameterValue": "arn:aws:lambda:region:account:function:log-processor"
            }
          ]
        }
      ]
    }
  }
}
```

시험 포인트:
- 실시간 로그 전송 + 최소 운영 오버헤드 = Kinesis Data Firehose

### 3. AWS Glue 구성 요소 관계

**Glue 종속성 및 워크플로우:**

```
Data Catalog (메타데이터 저장소)
    ↑
Crawler (스키마 자동 감지) → Job (ETL 처리)
    ↓                        ↓
Workflow (오케스트레이션)
    ↓
Trigger (실행 조건)
```

구성 요소별 역할:

**1. Data Catalog**
- 메타데이터 저장소
- 테이블/스키마 정의
- 파티션 정보 관리

**2. Crawler**
- 자동 스키마 감지
- Data Catalog 업데이트
- 새 파티션 발견

**3. Job**
- ETL 작업 실행
- Data Catalog 참조
- 데이터 변환/이동

**4. Workflow**
- Job과 Crawler 오케스트레이션
- 종속성 관리
- 실행 순서 제어

**5. Trigger**
- 스케줄 기반 실행
- 이벤트 기반 실행
- 조건부 실행

시험 포인트:
- Crawler → Data Catalog → Job → Workflow 순서로 종속성 이해

### 4. Glue Job Bookmarks - 증분 데이터 처리

**문제 시나리오**: Glue ETL 작업이 S3 전체 데이터 처리, 일일 증분 데이터만 처리 필요

**해결책: Job Bookmarks 활성화**

**Job Bookmarks 특징:**
- **상태 추적**: 마지막 처리 위치 기록
- **증분 처리**: 새로운 데이터만 처리
- **자동 관리**: Glue가 자동으로 상태 업데이트
- **DynamicFrame 통합**: 자동으로 새 파일만 읽기

Job Bookmarks 작동 원리:
```python
# Job Bookmarks 활성화된 Glue 작업
import sys
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from awsglue.context import GlueContext
from awsglue.job import Job

# Job Bookmarks 설정
args = getResolvedOptions(sys.argv, ['JOB_NAME'])
sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args['JOB_NAME'], args)

# DynamicFrame 읽기 (Job Bookmarks 자동 적용)
datasource = glueContext.create_dynamic_frame.from_catalog(
    database="my_database",
    table_name="s3_table",
    transformation_ctx="datasource"
)

# 변환 및 로드 작업...

# Job 완료 시 상태 커밋
job.commit()
```

Job Bookmarks vs 다른 방법들:

**Job Bookmarks 장점:**
- **코딩 불필요**: 설정만으로 증분 처리
- **자동 상태 관리**: Glue가 자동으로 처리 위치 추적
- **실패 복구**: 실패 지점부터 재시작

**파티션 기반 처리 단점:**
- **코딩 필요**: 날짜 기반 필터링 로직 구현
- **수동 관리**: 처리된 파티션 추적 필요

**파일명 필터링 단점:**
- **복잡한 로직**: 파일명 패턴 매칭 구현
- **에러 가능성**: 파일명 변경 시 문제 발생

설정 방법:
```json
{
  "DefaultArguments": {
    "--job-bookmark-option": "job-bookmark-enable"
  }
}
```

시험 포인트:
- 증분 데이터 처리 + 최소 코딩 노력 = Job Bookmarks

### 5. Kinesis Data Streams vs Data Firehose 비교

**핵심 차이점:**

| 특성 | Data Streams | Data Firehose |
|------|--------------|---------------|
| **관리 수준** | 수동 관리 (샤드) | 완전 관리형 |
| **지연시간** | 실시간 (밀리초) | 준실시간 (분) |
| **스케일링** | 수동 샤드 조정 | 자동 스케일링 |
| **대상** | 사용자 정의 애플리케이션 | 사전 정의된 대상 |
| **데이터 변환** | Lambda 수동 구성 | 내장 변환 |
| **비용** | 샤드 시간 기반 | 처리량 기반 |

**Data Streams 사용 사례:**
- 실시간 처리 필요
- 사용자 정의 처리 로직
- 복잡한 스트림 분석

**Data Firehose 사용 사례:**
- 데이터 로딩/아카이빙
- 완전 관리형 솔루션
- S3, Redshift, Splunk 등 지원 대상

시험 포인트:
- 실시간 = Data Streams
- 완전 관리형 + 지원 대상 = Data Firehose