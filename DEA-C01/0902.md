## 0902 (~page 10)

### 1. AWS Glue Workflows

정의: 여러 ETL 작업들을 조율하고 의존성을 관리하는 시각적 워크플로우 도구

핵심 특징:
- 의존성 관리: 작업 간 실행 순서 제어 (Job A 완료 후 Job B 실행)
- 조건부 분기: 성공/실패에 따른 다른 경로 실행
- 병렬 실행: 독립적인 작업들의 동시 실행
- 모니터링: CloudWatch와 통합된 실행 상태 추적

시험 포인트:
- 복잡한 ETL 파이프라인에서 작업 순서가 중요할 때 사용
- Trigger와 함께 사용하여 자동화 구현

Glue 작업 유형:
- Glue ETL 작업: Spark 기반, 서버리스
- Glue Python Shell 작업: 경량 Python 스크립트용
- Glue Ray 작업: 분산 Python 처리용

### 2. AWS Lake Formation

정의: 데이터 레이크 구축과 보안을 위한 완전 관리형 서비스

핵심 기능:
- 중앙집중식 보안: 행/열 수준 액세스 제어
- 데이터 카탈로그: 자동 메타데이터 수집 및 관리
- Blueprint: 일반적인 데이터 소스용 사전 구축된 템플릿
- Cross-account access: 계정 간 안전한 데이터 공유

시험 포인트:
- 다중 계정 환경에서 데이터 공유 시나리오
- 세밀한 권한 제어가 필요한 경우
- 데이터 거버넌스 요구사항

### 3. Athena Workgroup

정의: 쿼리 실행 환경을 논리적으로 분리하는 관리 단위

주요 기능:
- 비용 제어: 쿼리당 스캔 데이터 한도 설정
- 결과 위치: 쿼리 결과의 S3 저장 위치 지정
- 암호화: 결과 데이터 암호화 강제
- 성능 모니터링: CloudWatch 메트릭 수집

시험 포인트:
- 팀별/프로젝트별 리소스 분리
- 쿼리 비용 예산 관리
- 데이터 보안 요구사항

### 4. Glue FLEX Execution Class

정의: 사용한 리소스만큼 비용을 지불하는 온디맨드 실행 모델

Standard vs FLEX 비교:
- Standard: 최소 10분 요금, 예측 가능한 워크로드
- FLEX: 1분 단위 과금, 간헐적/예측 불가능한 워크로드

적용 시나리오:
- 개발/테스트 환경
- 불규칙한 스케줄의 ETL 작업
- 짧은 실행 시간의 작업

시험 포인트:
- 비용 최적화 시나리오에서 선택 기준

### 5. Snappy Compression

정의: Google이 개발한 고속 압축/해제 알고리즘

특징:
- 속도 우선: 압축률보다 속도에 최적화
- CPU 효율성: 낮은 CPU 오버헤드
- 빅데이터 친화적: Hadoop, Spark 생태계 표준

사용 사례:
- 실시간 스트리밍 데이터
- 중간 결과 저장
- 네트워크 전송 최적화

시험 포인트:
- 성능이 우선인 시나리오에서 선택
- Parquet 파일과 함께 사용

### 6. AWS Timestream

정의: 완전 관리형 시계열 데이터베이스

아키텍처:
- Memory Store: 최근 데이터 (고성능)
- Magnetic Store: 과거 데이터 (저비용)
- 자동 계층화: 데이터 수명주기 관리

핵심 기능:
- 자동 스케일링: 데이터 볼륨에 따른 자동 확장
- 내장 분석: 시계열 분석 함수 제공
- 압축: 자동 데이터 압축 (최대 1000:1)

시험 포인트:
- IoT, DevOps 모니터링 시나리오
- 시계열 데이터 분석 요구사항

### 7. AWS DataSync

정의: 온프레미스와 AWS 간 대용량 데이터 전송 서비스

핵심 기능:
- 증분 동기화: 변경된 데이터만 전송
- 스케줄링: 정기적 자동 동기화
- 데이터 검증: 전송 후 무결성 확인
- 대역폭 제어: 네트워크 사용량 조절

전송 대상:
- S3, EFS, FSx
- 온프레미스 NFS, SMB

시험 포인트:
- 대용량 일회성 마이그레이션
- 정기적 데이터 동기화 요구사항

### 8. AWS Glue Triggers

정의: Glue 작업 실행을 자동화하는 메커니즘

Trigger 유형:
- Schedule: Cron 표현식 기반 정기 실행
- Event: CloudWatch Events 기반 실행
- On-demand: 수동 실행
- Conditional: 다른 작업 완료 조건부 실행

시험 포인트:
- ETL 파이프라인 자동화
- 이벤트 기반 데이터 처리

### 9. Redshift Concurrency Scaling

정의: 동시 쿼리 증가 시 자동 클러스터 확장 기능

작동 방식:
- WLM Queue 설정: 대기열별 concurrency scaling 활성화
- 자동 확장: 쿼리 대기 시 추가 클러스터 생성
- 과금: 확장된 리소스 사용 시간만 과금

시험 포인트:
- 예측 불가능한 쿼리 부하 대응
- 성능 개선 vs 비용 최적화 균형

### 10. Glue PII Detection

정의: 개인식별정보를 자동 탐지하고 처리하는 변환

탐지 가능한 PII:
- 신용카드 번호, SSN, 이메일
- 전화번호, IP 주소
- 사용자 정의 패턴

처리 방법:
- Redaction: 완전 제거
- Masking: 일부 문자 마스킹
- Hashing: 해시값으로 대체

시험 포인트:
- 데이터 프라이버시 컴플라이언스
- GDPR, CCPA 요구사항 대응

### 11. Athena Federated Query

정의: 여러 데이터 소스를 하나의 쿼리로 조인하는 기능

지원 데이터 소스:
- RDS (MySQL, PostgreSQL)
- DynamoDB, DocumentDB
- Redis, ElastiCache
- 사용자 정의 커넥터

Lambda 기반 아키텍처:
- Data Source Connector를 Lambda로 구현
- 메타데이터와 데이터 처리 분리

시험 포인트:
- 하이브리드 데이터 분석 시나리오
- 실시간 운영 데이터와 분석 데이터 조인

### 12. EMR Graviton Instances

정의: ARM 기반 AWS Graviton 프로세서를 사용하는 EC2 인스턴스

장점:
- 비용 효율성: x86 대비 최대 20% 비용 절약
- 성능: 워크로드에 따라 동등하거나 더 나은 성능
- 에너지 효율성: 낮은 전력 소비

EMR 지원:
- Core nodes, Task nodes에 사용 가능
- Spark, Hive, Presto 등 주요 프레임워크 지원

시험 포인트:
- 비용 최적화 요구사항
- 대규모 데이터 처리 시나리오

### 13. Redshift External Schema & Materialized View

External Schema:
- 외부 데이터 소스를 Redshift에 매핑
- S3, RDS, Aurora 데이터 직접 쿼리 가능

Streaming Materialized View:
- 실시간 처리: Kinesis Data Streams 데이터를 실시간으로 처리
- Auto Refresh: 새 데이터 도착 시 자동 갱신
- 집계 연산: 스트리밍 데이터의 실시간 집계

시험 포인트:
- 실시간 분석 요구사항
- 스트리밍 데이터와 배치 데이터 통합 분석

### 14. AWS Step Functions Map State

정의: 병렬로 배열 항목들을 처리하는 상태

핵심 특징:
- 병렬 처리: 각 배열 요소를 독립적으로 동시 처리
- 동적 병렬성: 런타임에 결정되는 병렬 분기 수
- 최대 병렬성: 기본 40개, 최대 1000개 동시 실행
- 에러 처리: 각 항목별 개별 재시도/에러 처리

사용 사례:
- 여러 파일에 동일한 변환 적용
- 다중 데이터베이스 병렬 처리
- 배치 처리 작업 분산

시험 포인트:
- 대용량 데이터 파일 컬렉션의 병렬 처리 시나리오에서 정답


### 15. AWS Glue FindMatches ML Transform

정의: 머신러닝을 이용한 중복 데이터 자동 탐지 및 제거

작동 방식:
- 학습 단계: 샘플 데이터로 일치 패턴 학습
- 자동 탐지: 유사한 레코드 자동 식별
- 정확도 조정: Precision vs Recall 트레이드오프 설정
- 스케일: 대용량 데이터셋 처리 가능

기존 방법 대비 장점:
- Rule-based: 규칙 작성 복잡, 정확도 제한
- FindMatches: 자동 학습, 높은 정확도, 운영 오버헤드 최소

시험 포인트:
- 중복 제거 + 최소 운영 오버헤드 = FindMatches가 정답

### 16. A company uses Amazon RDS to store transactional data. The company runs an RDS DB instance in a private subnet. A developer wrote an AWS Lambda function with default settings to insert, update, or delete data in the DB instance.
The developer needs to give the Lambda function the ability to connect to the DB instance privately without using the public internet.
Which combination of steps will meet this requirement with the LEAST operational overhead? (Choose two.)

C Configure the Lambda function to run in the same subnet that the DB instance uses.
D Attach the same security group to the Lambda function and the DB instance. Include a self-referencing rule that allows access through the database port.

C. Lambda를 DB와 같은 서브넷에 구성
- Lambda를 VPC에 배치하여 프라이빗 연결 가능
- 같은 서브넷 = 같은 네트워크 세그먼트

D. 같은 보안 그룹 + 셀프 레퍼런싱 규칙
- 같은 보안 그룹의 리소스 간 통신 허용
- 셀프 레퍼런싱: 보안 그룹 자체를 소스로 지정

### 17. A company has a production AWS account that runs company workloads. The company's security team created a security AWS account to store and analyze security logs from the production AWS account. The security logs in the production AWS account are stored in Amazon CloudWatch Logs.
The company needs to use Amazon Kinesis Data Streams to deliver the security logs to the security AWS account.
Which solution will meet these requirements?

Create a destination data stream in the security AWS account. Create an IAM role and a trust policy to grant CloudWatch Logs the permission to put data into the stream. Create a subscription filter in the production AWS account.
Answer(s): D

아키텍처:
1. 보안 계정: Kinesis Data Stream 생성
2. 프로덕션 계정:
- CloudWatch Logs Subscription Filter 생성
- Cross-account IAM Role 생성
3. 권한 설정:
- Trust Policy: CloudWatch Logs 서비스가 역할 assume 가능
- Permission Policy: Kinesis에 데이터 put 권한

핵심 구성 요소:
- Destination Stream: 대상 계정의 Kinesis
- Cross-account Role: CloudWatch Logs가 사용할 역할
- Subscription Filter: 로그 스트리밍 트리거

### 18. Athena 성능 최적화 (Partition Index vs Projection)
- Create an AWS Glue partition index. Enable partition filtering
- Use Athena partition projection based on the S3 bucket prefix. -> 이 두개 athena bottleneck 해결 방안이라는데 설명좀요

**Glue Partition Index**

정의: Glue Data Catalog의 파티션 메타데이터 인덱싱

작동 방식:
- 파티션 메타데이터를 인덱스로 구성
- 쿼리 시 관련 파티션만 스캔
- 메타데이터 조회 성능 향상

적용 시나리오:
- 수천~수만 개의 파티션
- 복잡한 파티션 필터링 조건

**Athena Partition Projection**

정의: 메타데이터 없이 S3 경로 패턴으로 파티션 추론

작동 방식:
- S3 prefix 패턴 기반 자동 파티션 생성
- Glue Catalog 조회 없이 직접 S3 접근
- 동적 파티션 생성 (날짜, 시간 등)