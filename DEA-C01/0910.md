## 0910 (page ~80)

### 1. AWS Data Exchange - 서드파티 데이터 통합 최소화

**문제 시나리오**: 미디어 회사가 추천 시스템 개선을 위해 서드파티 데이터셋을 기존 분석 플랫폼에 통합, 최소한의 운영 오버헤드로 구현

**정답: A. AWS Data Exchange에서 API 호출로 서드파티 데이터셋 접근 및 통합**

**AWS Data Exchange란?**

**A. AWS Data Exchange 핵심 개념:**
- **데이터 마켓플레이스**: 서드파티 데이터 공급자와 소비자를 연결
- **관리형 서비스**: AWS가 데이터 전송, 과금, 라이센스 관리
- **API 기반 접근**: 프로그래밍 방식으로 데이터셋 구독 및 접근
- **자동 업데이트**: 데이터 공급자가 업데이트하면 자동으로 최신 데이터 제공

**B. 운영 오버헤드 최소화 장점:**
```python
# 기존 방식 (복잡한 통합)
# 1. 서드파티 API 연동 개발
# 2. 인증/인가 시스템 구축
# 3. 데이터 형식 변환 로직
# 4. 에러 처리 및 재시도 로직
# 5. 데이터 업데이트 감지 시스템

# Data Exchange 방식 (간단한 통합)
import boto3

data_exchange = boto3.client('dataexchange')

# 구독한 데이터셋 자동 다운로드
response = data_exchange.get_asset(
    AssetId='asset-id',
    DataSetId='dataset-id', 
    RevisionId='revision-id'
)
```

**C. 통합 아키텍처:**
```
서드파티 데이터 → Data Exchange → S3 → Glue ETL → 기존 분석 플랫폼
       ↑              ↑           ↑        ↑           ↑
    외부 데이터      관리형 서비스   자동 저장   변환 처리    추천 시스템
```

시험 포인트:
- **서드파티 데이터 통합** = AWS Data Exchange 활용
- **최소 운영 오버헤드** = 관리형 서비스의 자동화된 데이터 전송
- **API 기반 접근** = 프로그래밍 방식의 간편한 데이터 소비

### 2. Amazon Athena 파티션 성능 최적화 - 인덱스와 프로젝션

**문제 시나리오**: Athena 쿼리에서 S3의 많은 파티션으로 인한 쿼리 플랜 성능 병목, 쿼리 계획 시간 단축 필요

**정답: A. AWS Glue 파티션 인덱스 생성 + 파티션 필터링 활성화 + C. S3 버킷 prefix 기반 Athena 파티션 프로젝션**

**A. AWS Glue 파티션 인덱스의 효과:**

**파티션 인덱스 생성:**
```python
import boto3

glue = boto3.client('glue')

# 파티션 인덱스 생성
response = glue.create_partition_index(
    DatabaseName='analytics_db',
    TableName='user_events',
    PartitionIndex={
        'IndexName': 'date-region-index',
        'Keys': [
            {'Name': 'year', 'Type': 'string'},
            {'Name': 'month', 'Type': 'string'}, 
            {'Name': 'region', 'Type': 'string'}
        ]
    }
)
```

**성능 개선 효과:**
```
파티션 인덱스 없음:
10,000개 파티션 → 전체 파티션 메타데이터 스캔 → 30초 쿼리 플래닝

파티션 인덱스 적용:
10,000개 파티션 → 인덱스 기반 필터링 → 50개 관련 파티션만 확인 → 2초 쿼리 플래닝
```

**B. Athena 파티션 프로젝션의 장점:**

**파티션 프로젝션 설정:**
```sql
-- 테이블 프로퍼티에 파티션 프로젝션 설정
ALTER TABLE user_events SET TBLPROPERTIES (
  'projection.enabled' = 'true',
  'projection.year.type' = 'integer',
  'projection.year.range' = '2020,2030',
  'projection.month.type' = 'integer', 
  'projection.month.range' = '1,12',
  'projection.month.digits' = '2',
  'projection.day.type' = 'integer',
  'projection.day.range' = '1,31',
  'projection.day.digits' = '2',
  'storage.location.template' = 's3://bucket/data/year=${year}/month=${month}/day=${day}/'
);
```

**프로젝션 작동 원리:**
```
기존 방식 (메타스토어 의존):
쿼리 실행 → Glue Catalog 파티션 목록 조회 → 파티션 필터링 → S3 접근

파티션 프로젝션 (메타스토어 우회):
쿼리 실행 → 패턴 기반 파티션 계산 → 직접 S3 접근
```

**C. 두 솔루션의 시너지 효과:**

**복합 최적화 전략:**
1. **파티션 인덱스**: 기존 파티션들에 대한 빠른 메타데이터 접근
2. **파티션 프로젝션**: 새로운 파티션들에 대한 메타스토어 우회 접근

**성능 비교:**
```
최적화 전: 10,000 파티션 → 30초 쿼리 플래닝
파티션 인덱스만: 10,000 파티션 → 2초 쿼리 플래닝  
프로젝션만: 메타스토어 우회 → 0.5초 쿼리 플래닝
둘 다 적용: 최적의 방법 자동 선택 → 평균 0.3초 쿼리 플래닝
```

시험 포인트:
- **파티션 성능 병목** = 파티션 인덱스 + 파티션 프로젝션
- **메타데이터 최적화** = Glue Catalog 인덱스 활용
- **메타스토어 우회** = 파티션 프로젝션으로 직접 S3 접근

### 3. Amazon Redshift Data Sharing - 클러스터 간 데이터 공유

**문제 시나리오**: ETL용 Redshift 클러스터의 데이터를 BI용 Redshift 클러스터와 공유, 중요한 분석 작업 중단 없이 컴퓨팅 리소스 사용 최소화

**정답: A. Redshift 데이터 공유를 사용하여 영업팀 BI 클러스터를 ETL 클러스터의 소비자로 설정**

**A. Redshift Data Sharing 핵심 개념:**

**데이터 공유 아키텍처:**
```
Producer Cluster (ETL)     Consumer Cluster (BI)
┌─────────────────────┐    ┌──────────────────────┐
│ 실제 데이터 저장     │ ──► │ 가상 뷰로 데이터 접근 │
│ 컴퓨팅 리소스 사용   │    │ 컴퓨팅 리소스만 사용  │
│ 스토리지 비용 발생   │    │ 스토리지 비용 없음    │
└─────────────────────┘    └──────────────────────┘
```

**B. 데이터 공유 설정:**

**Producer 측 설정 (ETL 클러스터):**
```sql
-- 네임스페이스 생성
CREATE NAMESPACE etl_data_share;

-- 데이터 공유 생성
CREATE DATASHARE sales_data_share;

-- 테이블을 데이터 공유에 추가
ALTER DATASHARE sales_data_share 
ADD SCHEMA public;

ALTER DATASHARE sales_data_share 
ADD TABLE public.orders, public.customers, public.products;

-- 소비자 클러스터에 권한 부여
GRANT USAGE ON DATASHARE sales_data_share 
TO NAMESPACE 'consumer-cluster-namespace';
```

**Consumer 측 설정 (BI 클러스터):**
```sql
-- 데이터 공유에서 데이터베이스 생성
CREATE DATABASE shared_sales 
FROM DATASHARE sales_data_share 
OF NAMESPACE 'producer-cluster-namespace';

-- 공유된 데이터를 로컬 데이터와 조인
SELECT s.order_date, s.amount, l.campaign_id
FROM shared_sales.public.orders s
JOIN local_bi.public.campaigns l 
ON s.customer_id = l.customer_id;
```

**C. 왜 이 솔루션이 최적인가:**

**컴퓨팅 리소스 최소화:**
- ✅ **Producer 부하 없음**: ETL 클러스터는 데이터만 공유, 추가 쿼리 처리 안함
- ✅ **실시간 접근**: 별도 데이터 복사나 ETL 과정 불필요
- ✅ **스토리지 공유**: 동일 데이터를 중복 저장하지 않음

**중단 없는 운영:**
- **독립적 쿼리 실행**: BI 클러스터의 쿼리가 ETL 클러스터에 영향 없음
- **자동 동기화**: Producer 데이터 변경 시 Consumer에 즉시 반영
- **권한 제어**: 특정 테이블/스키마만 선택적 공유 가능

**D. 다른 옵션들과 비교:**

**데이터 복사 방식 (오답):**
- ❌ **스토리지 중복**: 동일 데이터를 두 번 저장
- ❌ **동기화 복잡성**: ETL과 BI 간 데이터 일관성 관리 필요
- ❌ **비용 증가**: 스토리지 비용 2배

**Federated Query (오답):**  
- ❌ **성능 저하**: 실시간 데이터 전송으로 지연 발생
- ❌ **네트워크 비용**: 클러스터 간 대량 데이터 이동
- ❌ **복잡한 조인**: 크로스 클러스터 조인 성능 문제

**E. 비용 및 성능 분석:**

**비용 구조:**
```
기존 방식 (데이터 복사):
ETL 클러스터: $1000/월 (4노드)
BI 클러스터: $800/월 (3노드) + $500/월 (중복 스토리지)
총 비용: $2300/월

Data Sharing 방식:
ETL 클러스터: $1000/월 (4노드, 공유 설정만)
BI 클러스터: $800/월 (3노드, 스토리지 비용 없음)  
총 비용: $1800/월 (22% 절약)
```

**성능 최적화:**
- **지연 시간**: 실시간 데이터 접근 (복사 지연 없음)
- **일관성**: 단일 원본으로 데이터 일관성 보장
- **확장성**: Producer/Consumer 독립적 스케일링

시험 포인트:
- **클러스터 간 데이터 공유** = Redshift Data Sharing
- **컴퓨팅 리소스 최소화** = Producer 클러스터 부하 없음
- **실시간 데이터 접근** = 별도 복사 없이 즉시 접근

### 4. Amazon EMR Graviton 인스턴스 - ARM 기반 성능 최적화

**문제 시나리오**: EMR 클러스터의 비용 최적화와 성능 향상

**정답: D. Core 노드와 Task 노드에 Graviton 인스턴스 사용**

**A. Graviton 인스턴스란?**

**ARM 기반 프로세서:**
- **AWS Graviton2/3**: ARM Neoverse 기반 커스텀 실리콘
- **에너지 효율성**: x86 대비 20% 더 높은 성능/전력 비율
- **비용 효율성**: 동등 성능 대비 최대 40% 비용 절감
- **EMR 최적화**: Spark, Hadoop, Hive 등 빅데이터 워크로드 최적화

**B. EMR에서 Graviton 인스턴스 활용:**

**지원되는 인스턴스 타입:**
```json
{
  "MasterInstanceType": "m6g.xlarge",    // Graviton2 범용
  "CoreInstanceType": "m6g.2xlarge",     // Graviton2 범용  
  "TaskInstanceType": "c6g.2xlarge"      // Graviton2 컴퓨팅 최적화
}
```

**성능/비용 비교:**
```
x86 인스턴스 (기존):
m5.2xlarge: 8 vCPU, 32GB RAM, $0.384/시간
c5.2xlarge: 8 vCPU, 16GB RAM, $0.34/시간

Graviton 인스턴스 (최적화):
m6g.2xlarge: 8 vCPU, 32GB RAM, $0.308/시간 (20% 절약)
c6g.2xlarge: 8 vCPU, 16GB RAM, $0.272/시간 (20% 절약)
```

**C. EMR 워크로드별 성능 향상:**

**Spark 작업 최적화:**
```python
# Spark 설정 최적화 (Graviton 인스턴스용)
spark_config = {
    "spark.sql.adaptive.enabled": "true",
    "spark.sql.adaptive.coalescePartitions.enabled": "true",
    "spark.serializer": "org.apache.spark.serializer.KryoSerializer",
    "spark.executor.cores": "4",  # Graviton의 멀티코어 활용
    "spark.executor.memory": "6g"
}
```

**성능 벤치마크:**
```
동일 Spark 작업 (10GB 데이터 처리):
x86 인스턴스: 45분
Graviton 인스턴스: 38분 (15% 성능 향상)

비용 분석 (100노드 클러스터, 일 8시간):
x86: $307.2/일
Graviton: $246.4/일 (20% 비용 절감)
```

**D. Graviton 사용 시 고려사항:**

**호환성:**
- ✅ **EMR 6.1+**: Graviton 인스턴스 완전 지원
- ✅ **주요 빅데이터 도구**: Spark, Hadoop, Hive, HBase 모두 지원
- ✅ **Java/Scala 애플리케이션**: JVM 기반 앱 완벽 호환
- ❓ **네이티브 바이너리**: ARM용 컴파일 필요 (드물게 발생)

**최적화된 구성:**
```bash
# EMR 클러스터 생성 (Graviton 인스턴스)
aws emr create-cluster \
  --name "Graviton-Optimized-Cluster" \
  --release-label emr-6.4.0 \
  --instance-groups \
    InstanceGroupType=MASTER,InstanceType=m6g.xlarge,InstanceCount=1 \
    InstanceGroupType=CORE,InstanceType=m6g.2xlarge,InstanceCount=4 \
    InstanceGroupType=TASK,InstanceType=c6g.2xlarge,InstanceCount=8 \
  --applications Name=Spark Name=Hadoop
```

**E. 비용 최적화 효과:**

**월간 비용 분석 (중간 규모 클러스터):**
```
기존 x86 구성:
Master: m5.xlarge × 1 = $140/월
Core: m5.2xlarge × 4 = $1,107/월  
Task: c5.2xlarge × 8 = $1,958/월
총 비용: $3,205/월

Graviton 구성:
Master: m6g.xlarge × 1 = $112/월 (20% 절약)
Core: m6g.2xlarge × 4 = $886/월 (20% 절약)
Task: c6g.2xlarge × 8 = $1,566/월 (20% 절약)  
총 비용: $2,564/월 (전체 20% 절약)

연간 절약액: $7,692
```

시험 포인트:
- **EMR 비용 최적화** = Graviton 인스턴스 활용
- **ARM 기반 성능 향상** = 에너지 효율적 프로세서
- **빅데이터 워크로드** = Spark, Hadoop 등 완전 호환

### 5. EC2 데이터 영속성 - EBS 볼륨 연결

**문제 시나리오**: EC2 인스턴스에서 생성되는 데이터를 인스턴스 종료 후에도 보존, AMI에서 새 인스턴스 시작 시 데이터 유지

**정답: EC2 인스턴스 스토어 볼륨 기반 AMI로 새 EC2 인스턴스 시작 + 애플리케이션 데이터용 Amazon EBS 볼륨 연결 + EC2 인스턴스에 기본 설정 적용**

**A. 인스턴스 스토어 vs EBS의 이해:**

**인스턴스 스토어 볼륨:**
- **임시 스토리지**: 인스턴스 종료 시 데이터 소실
- **고성능**: 물리적으로 연결된 SSD, 높은 I/O 성능
- **무료**: 인스턴스 타입에 포함된 스토리지
- **용도**: OS, 애플리케이션, 임시 파일

**EBS 볼륨:**
- **영구 스토리지**: 인스턴스와 독립적으로 데이터 보존
- **스냅샷 지원**: 백업 및 복원 가능
- **크기 조절**: 동적으로 볼륨 크기 변경 가능
- **용도**: 중요한 데이터, 데이터베이스, 로그

**B. 왜 이 구성이 정답인가:**

**데이터 분리 전략:**
```
┌─────────────────────┐    ┌──────────────────────┐
│ Instance Store      │    │ EBS Volume           │
│ - OS (임시)         │    │ - Application Data   │
│ - Application       │    │ - 영구 보존          │
│ - Temp Files        │    │ - 백업 가능          │
│ (인스턴스 종료시 삭제)│    │ (인스턴스와 독립적)   │
└─────────────────────┘    └──────────────────────┘
```

**영속성 보장:**
- **인스턴스 종료**: 인스턴스 스토어는 삭제, EBS는 보존
- **새 인스턴스 시작**: 동일 EBS 볼륨 재연결로 데이터 복원
- **AMI 활용**: 표준화된 환경 빠른 구축

**C. 구현 예시:**

**EBS 볼륨 연결:**
```bash
# EBS 볼륨 생성
aws ec2 create-volume \
  --size 100 \
  --volume-type gp3 \
  --availability-zone us-east-1a \
  --tag-specifications 'ResourceType=volume,Tags=[{Key=Name,Value=AppData}]'

# 인스턴스에 볼륨 연결
aws ec2 attach-volume \
  --volume-id vol-12345678 \
  --instance-id i-87654321 \
  --device /dev/sdf

# 파일시스템 생성 및 마운트
sudo mkfs -t ext4 /dev/xvdf
sudo mkdir /app-data
sudo mount /dev/xvdf /app-data

# 부팅시 자동 마운트 설정
echo '/dev/xvdf /app-data ext4 defaults,nofail 0 2' >> /etc/fstab
```

**애플리케이션 설정:**
```python
# 애플리케이션에서 EBS 볼륨 사용
import os

# 데이터 저장 경로를 EBS 볼륨으로 설정
DATA_PATH = '/app-data'  # EBS 볼륨 마운트 포인트
TEMP_PATH = '/tmp'       # 인스턴스 스토어 활용

def save_important_data(data):
    # 중요한 데이터는 EBS에 저장
    with open(f'{DATA_PATH}/important_data.json', 'w') as f:
        json.dump(data, f)

def save_temp_data(data):
    # 임시 데이터는 인스턴스 스토어에 저장
    with open(f'{TEMP_PATH}/temp_data.json', 'w') as f:
        json.dump(data, f)
```

**D. 다른 옵션들이 부적절한 이유:**

**모든 데이터를 인스턴스 스토어에 저장 (오답):**
- ❌ **데이터 소실**: 인스턴스 종료 시 모든 데이터 영구 삭제
- ❌ **백업 불가**: 스냅샷이나 백업 기능 없음

**EBS 루트 볼륨만 사용 (부분적):**
- 🔶 **가능하지만 비효율적**: OS와 데이터가 혼재
- 🔶 **성능 저하**: 단일 볼륨에 모든 I/O 집중
- 🔶 **관리 복잡성**: OS 업그레이드 시 데이터 영향

**E. 운영 고려사항:**

**백업 전략:**
```bash
# 정기적 스냅샷 생성
aws ec2 create-snapshot \
  --volume-id vol-12345678 \
  --description "Daily backup of application data"

# 자동 백업 스케줄 (Lambda + CloudWatch Events)
# 매일 자정에 스냅샷 생성 및 오래된 스냅샷 삭제
```

**모니터링:**
```python
# CloudWatch 메트릭 모니터링
import boto3

cloudwatch = boto3.client('cloudwatch')

# EBS 볼륨 사용률 모니터링
cloudwatch.put_metric_alarm(
    AlarmName='EBS-Volume-Usage',
    ComparisonOperator='GreaterThanThreshold',
    EvaluationPeriods=2,
    MetricName='VolumeUtilization',
    Threshold=80.0,  # 80% 사용 시 알람
    ActionsEnabled=True
)
```

시험 포인트:
- **데이터 영속성** = EBS 볼륨으로 중요 데이터 분리
- **인스턴스 스토어 활용** = OS와 임시 파일용
- **하이브리드 스토리지** = 성능과 영속성의 균형

### 6. AWS Glue FLEX 실행 클래스 - 비용 최적화

**문제 시나리오**: AWS Glue 작업을 매일 실행하되 특정 시간에 실행하거나 완료할 필요 없음, 가장 비용 효율적인 방법 필요

**정답: Glue 작업 속성에서 FLEX 실행 클래스 선택**

**A. Glue FLEX 실행 클래스란?**

**실행 클래스 비교:**
- **Standard 클래스**: 즉시 실행, 예측 가능한 시작 시간
- **FLEX 클래스**: 지연된 실행, 비용 최적화 우선

**FLEX 클래스 특징:**
```python
# FLEX 실행 클래스 설정
job_config = {
    "Name": "cost-optimized-etl",
    "ExecutionClass": "FLEX",  # 비용 최적화 모드
    "MaxCapacity": 10.0,
    "Timeout": 2880  # 48시간 (FLEX는 더 긴 타임아웃 허용)
}
```

**B. 비용 절약 메커니즘:**

**AWS의 유휴 용량 활용:**
```
Standard 클래스:
요청 즉시 → 전용 리소스 할당 → 표준 요금 ($0.44/DPU-hour)

FLEX 클래스:  
요청 대기 → 유휴 용량 활용 → 50% 할인 요금 ($0.22/DPU-hour)
```

**실행 지연 범위:**
- **일반적 지연**: 0~30분 (대부분의 경우)
- **최대 지연**: 수 시간 (리소스 부족 시)
- **SLA**: 특정 시간 보장 없음

**C. 언제 FLEX를 사용해야 하는가:**

**적합한 상황:**
- ✅ **배치 ETL 작업**: 특정 시간 완료 불필요
- ✅ **일일/주간 정기 작업**: 유연한 실행 시간 허용
- ✅ **비용 민감한 워크로드**: 50% 비용 절약 중요
- ✅ **개발/테스트 환경**: 즉시 실행 불필요

**부적합한 상황:**
- ❌ **실시간 처리**: 즉시 실행 필요
- ❌ **SLA 요구사항**: 정확한 완료 시간 필요
- ❌ **의존성 있는 작업**: 다른 작업이 결과 대기

**D. FLEX 클래스 설정 및 모니터링:**

**CloudFormation 템플릿:**
```yaml
GlueJob:
  Type: AWS::Glue::Job
  Properties:
    Name: FlexETLJob
    ExecutionClass: FLEX
    GlueVersion: "3.0"
    MaxCapacity: 5.0
    Command:
      Name: glueetl
      ScriptLocation: s3://bucket/scripts/etl-script.py
    DefaultArguments:
      "--enable-metrics": ""
      "--enable-continuous-cloudwatch-log": "true"
```

**비용 모니터링:**
```python
import boto3

# Glue 작업 실행 비용 추적
glue = boto3.client('glue')

def get_job_cost_comparison():
    job_runs = glue.get_job_runs(JobName='etl-job')['JobRuns']
    
    for run in job_runs:
        execution_time = run['ExecutionTime']  # 분 단위
        dpu_capacity = run['MaxCapacity']
        
        if run.get('ExecutionClass') == 'FLEX':
            cost = (execution_time / 60) * dpu_capacity * 0.22  # FLEX 요금
            print(f"FLEX 실행 비용: ${cost:.2f}")
        else:
            cost = (execution_time / 60) * dpu_capacity * 0.44  # Standard 요금
            print(f"Standard 실행 비용: ${cost:.2f}")
```

**E. 실제 비용 절약 사례:**

**일일 ETL 작업 (5 DPU, 2시간 실행):**
```
Standard 클래스:
비용 = 2시간 × 5 DPU × $0.44 = $4.4/일
월 비용 = $4.4 × 30일 = $132/월

FLEX 클래스:
비용 = 2시간 × 5 DPU × $0.22 = $2.2/일  
월 비용 = $2.2 × 30일 = $66/월

연간 절약액 = ($132 - $66) × 12개월 = $792
```

**대규모 배치 작업 (20 DPU, 4시간 실행, 주 3회):**
```
Standard: 4시간 × 20 DPU × $0.44 × 3회 × 52주 = $5,478/년
FLEX: 4시간 × 20 DPU × $0.22 × 3회 × 52주 = $2,739/년
절약액 = $2,739/년 (50% 절약)
```

**F. 모범 사례:**

**FLEX 작업 최적화:**
```python
# FLEX 작업에 적합한 설정
job_args = {
    "--enable-metrics": "",                    # 성능 모니터링
    "--enable-continuous-cloudwatch-log": "",  # 로그 스트리밍
    "--enable-spark-ui": "",                   # Spark UI 활성화
    "--job-max-capacity": "10",                # 적절한 DPU 설정
    "--conf": "spark.sql.adaptive.enabled=true"  # 적응형 쿼리 실행
}
```

**실행 시간 예측:**
- **히스토리 분석**: 과거 실행 패턴으로 지연 시간 예측
- **버퍼 시간**: 의존성 있는 후속 작업에 충분한 버퍼 제공
- **알림 설정**: 예상보다 오래 지연되는 경우 알람

시험 포인트:
- **비용 최적화** = FLEX 실행 클래스로 50% 절약
- **유연한 실행 시간** = 특정 시간 완료 불필요한 작업
- **유휴 용량 활용** = AWS 리소스 효율적 사용

### 7. Amazon Athena Workgroup - Spark 엔진 지원

**문제 시나리오**: Athena에서 CTAS를 사용한 SQL ETL을 Apache Spark를 사용한 분석으로 전환, Athena에서 Spark 접근 방법

**정답: Athena workgroup (Spark 엔진 지원)**

**A. Athena Workgroup이란?**

**워크그룹 핵심 개념:**
- **쿼리 실행 환경**: 사용자별/팀별 격리된 실행 환경
- **리소스 관리**: 쿼리당 데이터 스캔 제한, 비용 제어
- **엔진 선택**: SQL 엔진 또는 Apache Spark 엔진
- **설정 관리**: 결과 위치, 암호화, 태그 등 중앙 관리

**B. Spark 지원 Athena for Analytics:**

**Athena for Apache Spark 설정:**
```python
import boto3

athena = boto3.client('athena')

# Spark 엔진 워크그룹 생성
response = athena.create_work_group(
    Name='spark-analytics-workgroup',
    Description='Spark engine for advanced analytics',
    Configuration={
        'ResultConfiguration': {
            'OutputLocation': 's3://athena-results-bucket/spark-outputs/'
        },
        'EnforceWorkGroupConfiguration': True,
        'PublishCloudWatchMetrics': True,
        'EngineVersion': {
            'SelectedEngineVersion': 'Spark engine version 3',
            'EffectiveEngineVersion': 'Spark engine version 3'
        }
    }
)
```

**C. Spark 노트북 인터페이스:**

**Jupyter 노트북 통합:**
```python
# Athena Spark 세션 시작
from pyathena import connect
from pyathena.spark.session import get_spark_session

# Spark 세션 생성
spark = get_spark_session(
    work_group='spark-analytics-workgroup',
    s3_staging_dir='s3://athena-spark-staging/'
)

# DataFrame API 사용
df = spark.sql("""
    SELECT customer_id, product_category, 
           SUM(amount) as total_spent
    FROM sales_data 
    WHERE order_date >= '2024-01-01'
    GROUP BY customer_id, product_category
""")

# 머신러닝 라이브러리 활용
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.clustering import KMeans

assembler = VectorAssembler(
    inputCols=['total_spent', 'order_frequency'],
    outputCol='features'
)

feature_df = assembler.transform(df)
kmeans = KMeans(k=5, seed=1)
model = kmeans.fit(feature_df)
```

**D. SQL vs Spark 비교:**

**기존 SQL CTAS 방식:**
```sql
-- 제한적인 분석 기능
CREATE TABLE customer_segments AS
SELECT customer_id, 
       AVG(order_amount) as avg_order,
       COUNT(*) as order_count
FROM orders 
GROUP BY customer_id;
```

**Spark 방식:**
```python
# 고급 분석 및 머신러닝
from pyspark.ml.stat import Correlation
from pyspark.ml.feature import StandardScaler

# 통계 분석
correlation_matrix = Correlation.corr(df, 'features').head()[0]

# 실시간 스케일링
scaler = StandardScaler(inputCol="features", outputCol="scaledFeatures")
scaler_model = scaler.fit(df)
scaled_df = scaler_model.transform(df)

# 복잡한 윈도우 함수
from pyspark.sql.window import Window
from pyspark.sql.functions import lag, lead

window_spec = Window.partitionBy('customer_id').orderBy('order_date')
df_with_trends = df.withColumn('prev_amount', lag('amount').over(window_spec))
```

**E. 워크그룹 활용 시나리오:**

**팀별 분리:**
```python
# 데이터 사이언스 팀 워크그룹
ds_workgroup = {
    'Name': 'data-science-team',
    'Configuration': {
        'BytesScannedCutoffPerQuery': 1000000000000,  # 1TB 제한
        'EnforceWorkGroupConfiguration': True,
        'EngineVersion': 'Spark engine version 3'
    }
}

# BI 분석가 워크그룹  
bi_workgroup = {
    'Name': 'business-analysts',
    'Configuration': {
        'BytesScannedCutoffPerQuery': 100000000000,   # 100GB 제한
        'EnforceWorkGroupConfiguration': True,
        'EngineVersion': 'Athena engine version 2'    # SQL 엔진
    }
}
```

**비용 제어:**
```python
# 워크그룹별 비용 모니터링
def monitor_workgroup_costs(workgroup_name):
    cloudwatch = boto3.client('cloudwatch')
    
    # 데이터 스캔 비용 추적
    response = cloudwatch.get_metric_statistics(
        Namespace='AWS/Athena',
        MetricName='DataScannedInBytes',
        Dimensions=[
            {'Name': 'WorkGroup', 'Value': workgroup_name}
        ],
        StartTime=datetime.utcnow() - timedelta(days=30),
        EndTime=datetime.utcnow(),
        Period=86400,  # 일별
        Statistics=['Sum']
    )
    
    # 비용 계산 ($5 per TB scanned)
    total_bytes = sum(point['Sum'] for point in response['Datapoints'])
    cost = (total_bytes / (1024**4)) * 5  # TB 당 $5
    
    return cost
```

**F. Spark 엔진의 장점:**

**고급 분석 기능:**
- ✅ **머신러닝**: MLlib 라이브러리 활용
- ✅ **스트림 처리**: 준실시간 데이터 처리  
- ✅ **그래프 분석**: GraphX API 지원
- ✅ **복잡한 ETL**: 다단계 변환 파이프라인

**확장성:**
```python
# 자동 스케일링
spark.conf.set("spark.sql.adaptive.enabled", "true")
spark.conf.set("spark.sql.adaptive.coalescePartitions.enabled", "true")  
spark.conf.set("spark.sql.adaptive.advisoryPartitionSizeInBytes", "128MB")
```

**통합성:**
- **S3 네이티브**: Parquet, Delta Lake 형식 지원
- **Glue Catalog**: 메타데이터 자동 통합
- **IAM**: 세밀한 접근 권한 제어

시험 포인트:
- **Athena Spark 지원** = 워크그룹의 엔진 설정
- **SQL에서 Spark 전환** = 고급 분석 및 머신러닝 활용
- **팀별 리소스 관리** = 워크그룹 기반 비용/권한 제어